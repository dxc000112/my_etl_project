# complete_project/dags/etl_dag.py
import os
import sys
from datetime import datetime, timedelta
import logging
import random

# æ·»åŠ  scripts è·¯å¾„åˆ° sys.pathï¼Œæ–¹ä¾¿å¯¼å…¥æ¨¡å—
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'scripts'))

from airflow import DAG
from airflow.operators.python import PythonOperator, BranchPythonOperator
from load_data import load_to_gcs

# æ¨¡æ‹Ÿ Slack æŠ¥è­¦ï¼ˆæ‰“å°ï¼‰
def slack_alert(context):
    task_id = context.get("task_instance").task_id
    dag_id = context.get("dag").dag_id
    print(f"[â—ï¸æé†’] DAG `{dag_id}` ä¸­ä»»åŠ¡ `{task_id}` æ‰§è¡Œå¤±è´¥ï¼")

# æ•°æ®éªŒè¯ä»»åŠ¡
def validate_data():
    logging.info("ðŸ” æ­£åœ¨éªŒè¯æ•°æ®...")
    data = ["sample"]  # æ”¹æˆç©ºåˆ—è¡¨å¯æ¨¡æ‹Ÿå¤±è´¥
    if not data:
        raise ValueError("âŒ æ•°æ®ä¸ºç©ºï¼Œç»ˆæ­¢æ‰§è¡Œ")
    logging.info("âœ… æ•°æ®éªŒè¯é€šè¿‡")

# åˆ†æ”¯å†³ç­–å‡½æ•°
def choose_path():
    decision = random.choice(["load_task", "stop_task"])
    logging.info(f"âœ¨ åˆ†æ”¯é€‰æ‹©ç»“æžœï¼š{decision}")
    return decision

# åœæ­¢æ‰§è¡Œä»»åŠ¡
def stop_task():
    logging.info("ðŸ›‘ æ¡ä»¶ä¸æ»¡è¶³ï¼Œä»»åŠ¡ç»ˆæ­¢")

# DAG å‚æ•°
def_args = {
    'owner': 'airflow',
    'start_date': datetime(2024, 3, 1),
    'retries': 2,
    'retry_delay': timedelta(minutes=3),
    'on_failure_callback': slack_alert
}

# å®šä¹‰ DAG
with DAG(
    dag_id="complete_etl_project",
    default_args=def_args,
    description="å®Œæ•´ ETL é¡¹ç›® DAG",
    schedule_interval="@daily",
    catchup=False
) as dag:

    validate = PythonOperator(
        task_id="validate_data",
        python_callable=validate_data
    )

    branch = BranchPythonOperator(
        task_id="branch_decision",
        python_callable=choose_path
    )

    load = PythonOperator(
        task_id="load_task",
        python_callable=load_to_gcs
    )

    stop = PythonOperator(
        task_id="stop_task",
        python_callable=stop_task
    )

    validate >> branch >> [load, stop]
